{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news.ipynb",
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "12vjuTdIIxEl9yn3_VpslJFgemowuqHiX",
      "authorship_tag": "ABX9TyOBhH8GK7Egwc+q0oThluoR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/ml0804/blob/master/news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGAFCUBmn29M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "path = \"drive/My Drive/news/chinese_news_trans.zip\"\n",
        "f = zipfile.ZipFile(path)\n",
        "f.extractall(\"train\")\n",
        "path = \"drive/My Drive/news/chinese_news_test.zip\"\n",
        "f = zipfile.ZipFile(path)\n",
        "f.extractall(\"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXga2DBDpIEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "def getdata(base):\n",
        "    contents = []\n",
        "    types = []\n",
        "    for dir in glob.glob(os.path.join(base, \"*\")):\n",
        "        t = os.path.split(dir)[-1]\n",
        "        for fn in glob.glob(os.path.join(dir, \"*.txt\")) + glob.glob(os.path.join(dir, \"*.TXT\")):\n",
        "            with open(fn) as f:\n",
        "                contents.append(f.read())\n",
        "                types.append(t)\n",
        "    df = pd.DataFrame({\n",
        "        \"content\":contents,\n",
        "        \"ans\":types\n",
        "    })\n",
        "    return df\n",
        "train_df = getdata(\"train/chinese_news_trans\")\n",
        "train_df\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA7el4jsre-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = getdata(\"test/chinese_news_test\")\n",
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qKVUPV30IKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 答案: Series.replace({\"李白\":0, \"杜甫\":1})\n",
        "# unique/value_counts\n",
        "u = train_df[\"ans\"].unique()\n",
        "trans = {n:i for i, n in enumerate(u)}\n",
        "trans_r = {i:n for i, n in enumerate(u)}\n",
        "y_train = train_df[\"ans\"].replace(trans)\n",
        "y_test = test_df[\"ans\"].replace(trans)\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP7USwfe0Sbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Series.apply(func)\n",
        "import jieba\n",
        "from urllib.request import urlretrieve\n",
        "url = \"https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big\"\n",
        "urlretrieve(url, \"dict.txt.big\")\n",
        "jieba.set_dictionary(\"dict.txt.big\")\n",
        "def poemcut(p):\n",
        "    return \" \".join(jieba.cut(p))\n",
        "x_train = train_df[\"content\"].apply(poemcut)\n",
        "x_test = test_df[\"content\"].apply(poemcut)\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUmXvzDA0vqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vec = CountVectorizer()\n",
        "x_train_count = vec.fit_transform(x_train)\n",
        "x_test_count = vec.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbRNuHG50zmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB(alpha=0.1)\n",
        "clf.fit(x_train_count, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG50auuT0_mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "pre = clf.predict(x_test_count)\n",
        "accuracy_score(pre, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o4Coiv91KAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = input(\"輸入一首新聞:\")\n",
        "count = vec.transform([poemcut(p)])\n",
        "proba = clf.predict_proba(count)[0]\n",
        "for name, prob in zip(u, proba):\n",
        "    print(name, \"的機率:\", round(prob, 2))\n",
        "# argmax: 找最大值的index\n",
        "print(\"成分最高;\", u[proba.argmax()])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}